{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running functions from post_scraping_text_processing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions loaded\n"
     ]
    }
   ],
   "source": [
    "%run ../scripts/post_scraping_text_processing.py functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../assets/lyrics/master_data_20180626.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['real_name', 'title', 'english_score'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15691, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to start more cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three immediate transformations:\n",
    "- get rid of the 'text' that's just saying that this is an instrumental song with no words.\n",
    "- replace the weird Ã— character with a real x (only found in songs with something like x2 in it, which I think I should build a function to handle eventually anyway)\n",
    "- get rid of songs with ANY non-Latin characters (there aren't many)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['text'].str.contains('ÅarkÄ± enstrÃ¼mantal olduÄŸu iÃ§in ÅŸarkÄ± sÃ¶zÃ¼ bulunmamaktadÄ±r.'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('Ã—', 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_latin_chars = '[ÎŒÎ“ÎœÎÎ¤Î§Î¬Î­Î®Î¯Î±Î³Î´ÎµÎ¶Î·Î¸Î¹ÎºÎ»Î¼Î½Î¿Ï€ÏÏ‚Ï„Ï…Ï†Ï‡ÏˆÏ‰ÏŒĞ‘Ğ“Ğ”Ğ—ĞšĞœĞĞĞŸĞ¡Ğ¢Ğ§Ğ©Ğ°Ğ±Ğ²Ğ³Ğ´ĞµĞ¶Ğ·Ğ¸Ğ¹ĞºĞ»Ğ¼Ğ½Ğ¾Ğ¿Ñ€ÑÑ‚ÑƒÑ„Ñ…Ñ†Ñ‡ÑˆÑ‰ÑŠÑÑÑ•Ø§Ø¨ØªØ¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¹ÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠ]'\n",
    "df = df[~(df['text'].str.contains(non_latin_chars))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harder choices: the other bad chars\n",
    "- Most songs with characters like Ã© aren't in Turkish, but some still are.\n",
    "- Steps:\n",
    "  - copy the corpus and explore it\n",
    "  - pull out bad Latin characters (not punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['text'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285    AltÄ±n yÃ¼zÃ¼ÄŸÃ¼m kÄ±rÄ±ldÄ± (hey) Suya dÃ¼ÅŸtÃ¼ su duru...\n",
       "286    Bir baÄŸ bozumuydu gidiÅŸin Plajlar boÅŸalmÄ±ÅŸtÄ± B...\n",
       "289    Bir of Ã§eksem karÅŸÄ± ki daÄŸlar yÄ±kÄ±lÄ±r BugÃ¼n po...\n",
       "292    EÄŸin dedikleri (anam) bir kÃ¼Ã§Ã¼k ÅŸehir (nidem) ...\n",
       "296    SubhanÄ±m Allah, sultanÄ±m Allah, MaÄŸrifet eden ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.map(remove_and_reg)\n",
    "corpus = corpus.map(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'â€UÃ¥\\ufeffÃƒKmwÃÃªrÃ›Ã²Ã‹Â¸yeÌ‡Ä±i Ã«LÂ²NRÃ <|Ã¦Câ€™b`]Â£Ã´Â¡ÃœDjÅ“Â¢Â»$ÄÃ¾Ã¶+Ã¡gÂ¿â€a5tfÃ‡3&*ÃºhWÃ‚[Å¾Ã©GvÂ¶ÄŸÂ¦Ã¹Ã±kï¿½sÃ­TÃ»ÃŸ>%ÃˆAÃ“Ã¯Ã½EYÄ°1â€šÃ£Ã‘qdFâ€²_Å¡7zI}ğŸ˜‚Ã¬cPMÃ¢Å‘HÃ¤Ã¼ÄÂ®â€˜#Ã¨4ÃšÅŸâ€“p8Ã°â€¦Ã¸luV6ËŠ=B-oÃ³OnZÃ§Ã®xJÂªS~{Xâ€œ9Ã–Ã‰0ÅQ2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_letters = \"\".join(corpus)\n",
    "\"\".join(set(corpus_letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.map(lambda x: x.replace('ï¿½', ''))\n",
    "corpus = corpus.map(lambda x: x.replace('ğŸ˜‚', ''))\n",
    "corpus = corpus.map(lambda x: x.replace('Â²', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "latin_bad_chars_regex = '[Ã¥Ã¯ÃŸÂ£Ã°Ã‰Â¡Ã¤Å¾Ã“Â¢ÃÄÃ‘Ã©Ã±Â¿Ã«ÃºÃ¬Ã Ã‹ÃˆÂ®Ã²ÃƒÂ¶Å¡Å‘Ã£Ã½Ã¾Ã¨Ã³Ã¦Ã¡ÃšÅ“Ã›Ã­Ã¹Ã¸Âª]' # bÌ‡ apparently meets b, ï¿½ should be apostrophe, ğŸ˜‚ should be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Ã¥Ã¯ÃŸÂ£Ã°Ã‰Â¡Ã¤Å¾Ã“Â¢ÃÄÃ‘Ã©Ã±Â¿Ã«ÃºÃ¬Ã Ã‹ÃˆÂ®Ã²ÃƒÂ¶Å¡Å‘Ã£Ã½Ã¾Ã¨Ã³Ã¦Ã¡ÃšÅ“Ã›Ã­Ã¹Ã¸Âª]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_bad_chars_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Geceler yarim oldu Anam anam garibem AÄŸlamak kÃ¡rim oldu Anam anam anam garibem Her dertten yÄ±kÄ±lmazdÄ±m Anam anam garibem Sebebim zalim oldu Anam anam anam garibem Bayram gelmiÅŸ neyime Anam anam garibem Kan damlar yÃ¼reÄŸime Anam anam anam garibem YaralarÄ±m sÄ±zlÄ±yor Anam anam garibem Doktor gelmiÅŸ neyime Anam anam anam garibem... '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[corpus.str.contains(latin_bad_chars_regex)].loc[10877,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>text</th>\n",
       "      <th>release</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Adx</td>\n",
       "      <td>ExÃ©cution</td>\n",
       "      <td>Fils d'Agrippine et de Germanicus Tu es devenu...</td>\n",
       "      <td>1998-01-01</td>\n",
       "      <td>Caligula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>Adx</td>\n",
       "      <td>Immortel</td>\n",
       "      <td>Regardez-moi si vous l'osez, Je vous respire C...</td>\n",
       "      <td>2011-10-17</td>\n",
       "      <td>Immortel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Adx</td>\n",
       "      <td>ExÃ©cution</td>\n",
       "      <td>On ne sait pas d'oÃ¹ il vient Ni comment il a f...</td>\n",
       "      <td>1998-01-01</td>\n",
       "      <td>L'Ã©tranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>Agony</td>\n",
       "      <td>Millennium</td>\n",
       "      <td>Frente nacional uniÃ³n Cero participaciÃ³n No ha...</td>\n",
       "      <td>1996-08-01</td>\n",
       "      <td>Guerrillas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>Alizee</td>\n",
       "      <td>taxedomask</td>\n",
       "      <td>Le monde est aux blondes dÃ©colorÃ©es J'annonce ...</td>\n",
       "      <td>2014-06-23</td>\n",
       "      <td>Blonde</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist       album                                               text  \\\n",
       "1000     Adx   ExÃ©cution  Fils d'Agrippine et de Germanicus Tu es devenu...   \n",
       "1007     Adx    Immortel  Regardez-moi si vous l'osez, Je vous respire C...   \n",
       "1014     Adx   ExÃ©cution  On ne sait pas d'oÃ¹ il vient Ni comment il a f...   \n",
       "1212   Agony  Millennium  Frente nacional uniÃ³n Cero participaciÃ³n No ha...   \n",
       "2365  Alizee  taxedomask  Le monde est aux blondes dÃ©colorÃ©es J'annonce ...   \n",
       "\n",
       "         release        name  \n",
       "1000  1998-01-01    Caligula  \n",
       "1007  2011-10-17    Immortel  \n",
       "1014  1998-01-01  L'Ã©tranger  \n",
       "1212  1996-08-01  Guerrillas  \n",
       "2365  2014-06-23      Blonde  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[corpus.str.contains(latin_bad_chars_regex)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get rid of the songs that have bad characters but exclude the Turkish ones:\n",
    "- make a list of the indexes for Turkish-language lyrics that nevertheless contain bad Latin chars (Turkish exceptions)\n",
    "- make a list of the index of the entries that have the bad Latin characters\n",
    "- drop the Turkish exceptions from that list\n",
    "- use that list to filter the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sabah uyandÄ±m, yanÄ±mda yoksun Solumda bir acÄ±, senden yoksun Soluksuz kaldÄ±m kÃ¶ÅŸelerde YalnÄ±zÄ±m, sanki yorgun Ä°nan, deÄŸildi sonsuz Bitti gitti seyrettik aÅŸkÄ± SanmÄ±ÅŸÄ±m yolu yordamÄ± bu BÃ¶yle yazÄ±lmadÄ± ya da ben Ã¶yle kandÄ±m Åimdi, tek baÅŸÄ±mayken, Kimin Ã¶ykÃ¼sÃ¼ bu ? [NakaratÂ²] Bu benim Ã¶ykÃ¼m, birazcÄ±k yaralÄ± Kalbimin pek Ã§ok yeri yamalÄ± Kan akar kanadÄ±mdan DÃ¼ÅŸer yere, yere kalanÄ± BirazcÄ±k yaralÄ±... Yeri yamalÄ±... Akar kanadÄ±mdan.. Geri kalanÄ±... YamalÄ± yamalÄ±... '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[51041, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_bad_chars = [53589, 53602, 7199, 10877, 14731, 51120, 53602, 54753, 19378, 20366, 21101, 22154, 22157, 27489, 28398, 38708, 49124]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_turkish_index = corpus[corpus.str.contains(latin_bad_chars_regex)].index\n",
    "non_turkish_index = corpus[non_turkish_index].drop(tr_bad_chars).index\n",
    "df = df.drop(non_turkish_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15484, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Taleal bedru aleyna Min seniyyatil veda VecebeÅŸ ÅŸÃ¼krÃ¼ aleyna Veda alil lehida Ay doÄŸdu Ã¼zerimize Veda tepelerinden ÅÃ¼kÃ¼r gerekti bizlere Allah'a davetinden EyyÃ¼hel meb'u sÃ¼fina Ci'te bil emril mut'a Ci'te ÅŸerreftel medina Merhaben ya hayra da \""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[453, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining this into a function, which can be found in the scripts subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../assets/lyrics/master_data_20180626.csv\", index_col=0)\n",
    "\n",
    "def grooming_language(df):\n",
    "    \"\"\"Takes a dataframe and performs 6 steps:\n",
    "        - gets rid of unnecessary columns\n",
    "        - gets rid of instrumental songs\n",
    "        - replaces some dumb characters\n",
    "        - gets rid on non-latin character songs\n",
    "        - gets rid of Turkish non-latin character songs\"\"\"\n",
    "    # Step 1: get rid of unnecessary columns, do initial corpus preparation\n",
    "    df.drop(['real_name', 'title', 'english_score'], axis = 1, inplace=True)\n",
    "    df.drop(28398, inplace = True)\n",
    "    df['text'] = df['text'].map(remove_and_reg)\n",
    "    df['text'] = df['text'].map(remove_punctuation)\n",
    "\n",
    "    # Step 2: get rid of instrumental songs\n",
    "    df = df[~(df['text'].str.contains('ÅarkÄ± enstrÃ¼mantal olduÄŸu iÃ§in ÅŸarkÄ± sÃ¶zÃ¼ bulunmamaktadÄ±r.'))]\n",
    "    \n",
    "    # Step 3: replace the weird x with regular x\n",
    "    df['text'] = df['text'].str.replace('Ã—', 'x')\n",
    "    \n",
    "    # Step 4: get rid of non-Latin songs\n",
    "    non_latin_chars = '[ÎŒÎ“ÎœÎÎ¤Î§Î¬Î­Î®Î¯Î±Î³Î´ÎµÎ¶Î·Î¸Î¹ÎºÎ»Î¼Î½Î¿Ï€ÏÏ‚Ï„Ï…Ï†Ï‡ÏˆÏ‰ÏŒĞ‘Ğ“Ğ”Ğ—ĞšĞœĞĞĞŸĞ¡Ğ¢Ğ§Ğ©Ğ°Ğ±Ğ²Ğ³Ğ´ĞµĞ¶Ğ·Ğ¸Ğ¹ĞºĞ»Ğ¼Ğ½Ğ¾Ğ¿Ñ€ÑÑ‚ÑƒÑ„Ñ…Ñ†Ñ‡ÑˆÑ‰ÑŠÑÑÑ•Ø§Ø¨ØªØ¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¹ÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠ]'\n",
    "    df = df[~(df['text'].str.contains(non_latin_chars))]\n",
    "\n",
    "    # Step 5: Replace some obvious non-issues\n",
    "    df['text'] = df['text'].map(lambda x: x.replace('ï¿½', ''))\n",
    "    df['text'] = df['text'].map(lambda x: x.replace('ğŸ˜‚', ''))\n",
    "    df['text'] = df['text'].map(lambda x: x.replace('Â²', ''))\n",
    "    \n",
    "    # Step 6: Take out the non-Turkish Latin-character songs\n",
    "    latin_bad_chars_regex = '[Ã¥Ã¯ÃŸÂ£Ã°Ã‰Â¡Ã¤Å¾Ã“Â¢ÃÄÃ‘Ã©Ã±Â¿Ã«ÃºÃ¬Ã Ã‹ÃˆÂ®Ã²ÃƒÂ¶Å¡Å‘Ã£Ã½Ã¾Ã¨Ã³Ã¦Ã¡ÃšÅ“Ã›Ã­Ã¹Ã¸Âª]'\n",
    "    tr_bad_chars = [53589, 53602, 7199, 10877, 14731, 51120, 53602, 54753, 19378, 20366, 21101, 22154, 22157, 27489, 28398, 38708, 49124]\n",
    "    non_turkish_index = corpus[corpus.str.contains(latin_bad_chars_regex)].index\n",
    "    non_turkish_index = corpus[non_turkish_index].drop(tr_bad_chars).index\n",
    "    df = df.drop(non_turkish_index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = grooming_language(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15523, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to check what's left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>text</th>\n",
       "      <th>release</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>Atilla TaÅŸ</td>\n",
       "      <td>Bir Atilla TaÅŸ AlbÃ¼mÃ¼</td>\n",
       "      <td>Bekarlar bekarlar Nasil yatarlar Anam yok Baba...</td>\n",
       "      <td>2007-05-04</td>\n",
       "      <td>Bekarlar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10877</th>\n",
       "      <td>BÃ¼lent Ersoy</td>\n",
       "      <td>Beddua</td>\n",
       "      <td>Geceler yarim oldu Anam anam garibem AÄŸlamak k...</td>\n",
       "      <td>1991-11-29</td>\n",
       "      <td>Geceler Yarim Oldu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14731</th>\n",
       "      <td>Cem Karaca</td>\n",
       "      <td>Yiyin Efendiler</td>\n",
       "      <td>Alamanya Ã‡ok uzaktan fetva ile bilinmez Alaman...</td>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>Alamanya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19378</th>\n",
       "      <td>Edip Akbayram</td>\n",
       "      <td>Bir ÅarkÄ±n Olsun DudaklarÄ±nda</td>\n",
       "      <td>Bu toprakta kalÄ±r adÄ±n TohumlarÄ±n arasÄ±nda YeÅŸ...</td>\n",
       "      <td>1993-06-28</td>\n",
       "      <td>AÄŸÄ±t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20366</th>\n",
       "      <td>Emrah</td>\n",
       "      <td>Sen GÃ¼lÃ¼nce</td>\n",
       "      <td>BEN GURBETIN KUCAGINDA DÃœSÃ‰ KALKA YORULDUM BIR...</td>\n",
       "      <td>1991-08-06</td>\n",
       "      <td>Ä°ki GÃ¶zÃ¼m Ä°ki Ã‡eÅŸme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21101</th>\n",
       "      <td>Erkan OÄŸur</td>\n",
       "      <td>deli sevda</td>\n",
       "      <td>Siyah perÃ§emlerin gonca yÃ¼zlerin Garip bÃ¼lbÃ¼l ...</td>\n",
       "      <td>2001-08-23</td>\n",
       "      <td>Siyah PerÃ§emlerin Gonca YÃ¼zlerin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22154</th>\n",
       "      <td>Fatih YeÅŸilgÃ¼l</td>\n",
       "      <td>AÄŸlama</td>\n",
       "      <td>Bilmez misin ben bir tek sana yandÄ±m yine sana...</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>CanÄ±na KÄ±yamadÄ±m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22157</th>\n",
       "      <td>Fatih YeÅŸilgÃ¼l</td>\n",
       "      <td>AÄŸlama</td>\n",
       "      <td>Son noktasÄ±na kadar sÃ©N yazdÄ±rdÄ±n sonunda yaln...</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>Ä°nadÄ±na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27489</th>\n",
       "      <td>HÃ¼lya AvÅŸar</td>\n",
       "      <td>HerÅŸey GÃ¶nlÃ¼nce Olsun</td>\n",
       "      <td>Kalplerimiz bir olsa SevdamÄ±z baÅŸka baÅŸka Olsu...</td>\n",
       "      <td>1989-06-13</td>\n",
       "      <td>Kalplerimiz Bir Olsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38708</th>\n",
       "      <td>Nihan</td>\n",
       "      <td>Terk-i Diyar</td>\n",
       "      <td>oturdugu yerden kaLkmas hicÃŸirseyi umursamaz i...</td>\n",
       "      <td>2005-09-13</td>\n",
       "      <td>KÄ±mÄ±lda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49124</th>\n",
       "      <td>Taner Olgun</td>\n",
       "      <td>Be GÃ¼lÃ¼m</td>\n",
       "      <td>Sevdaya DÃ¼ÅŸeli Yaram Derindir SÃ¶yleyin Dostlar...</td>\n",
       "      <td>2004</td>\n",
       "      <td>Sevdaya DÃ¼ÅŸeli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51120</th>\n",
       "      <td>Tuncay Tuncel</td>\n",
       "      <td>Okul Yolunda</td>\n",
       "      <td>Hani cok sevmistin beni ne oldu sana gÃ¼lÃ¼m Ner...</td>\n",
       "      <td>2001-03-16</td>\n",
       "      <td>GÃ¼lÃ¼m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53589</th>\n",
       "      <td>Yeni TÃ¼rkÃ¼</td>\n",
       "      <td>AÅŸk Yeniden</td>\n",
       "      <td>AÄŸÄ±r kapÄ± aksak lisan Kelimeler yetmiyor Ã‡Ä±pla...</td>\n",
       "      <td>1996-08-26</td>\n",
       "      <td>AÄŸÄ±r KapÄ±</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53602</th>\n",
       "      <td>Yeni TÃ¼rkÃ¼</td>\n",
       "      <td>Vira Vira</td>\n",
       "      <td>Bir Ã§apkÄ±n dilencidansederek gezip durur ÅŸehri...</td>\n",
       "      <td>2001</td>\n",
       "      <td>Bir Ã‡apkÄ±n Dilenci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54753</th>\n",
       "      <td>Zara</td>\n",
       "      <td>BÃ¼lbÃ¼l-i Åeyda</td>\n",
       "      <td>Ah Nice bir uyursun uyanmaz mÄ±sÄ±n GÃ¶cdÃ¼ kervan...</td>\n",
       "      <td>2005-09-29</td>\n",
       "      <td>Ah Nice Bir Uyursun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               artist                          album  \\\n",
       "7199       Atilla TaÅŸ          Bir Atilla TaÅŸ AlbÃ¼mÃ¼   \n",
       "10877    BÃ¼lent Ersoy                         Beddua   \n",
       "14731      Cem Karaca                Yiyin Efendiler   \n",
       "19378   Edip Akbayram  Bir ÅarkÄ±n Olsun DudaklarÄ±nda   \n",
       "20366           Emrah                    Sen GÃ¼lÃ¼nce   \n",
       "21101      Erkan OÄŸur                     deli sevda   \n",
       "22154  Fatih YeÅŸilgÃ¼l                         AÄŸlama   \n",
       "22157  Fatih YeÅŸilgÃ¼l                         AÄŸlama   \n",
       "27489     HÃ¼lya AvÅŸar          HerÅŸey GÃ¶nlÃ¼nce Olsun   \n",
       "38708           Nihan                   Terk-i Diyar   \n",
       "49124     Taner Olgun                       Be GÃ¼lÃ¼m   \n",
       "51120   Tuncay Tuncel                   Okul Yolunda   \n",
       "53589      Yeni TÃ¼rkÃ¼                    AÅŸk Yeniden   \n",
       "53602      Yeni TÃ¼rkÃ¼                      Vira Vira   \n",
       "54753            Zara                 BÃ¼lbÃ¼l-i Åeyda   \n",
       "\n",
       "                                                    text     release  \\\n",
       "7199   Bekarlar bekarlar Nasil yatarlar Anam yok Baba...  2007-05-04   \n",
       "10877  Geceler yarim oldu Anam anam garibem AÄŸlamak k...  1991-11-29   \n",
       "14731  Alamanya Ã‡ok uzaktan fetva ile bilinmez Alaman...  2017-06-09   \n",
       "19378  Bu toprakta kalÄ±r adÄ±n TohumlarÄ±n arasÄ±nda YeÅŸ...  1993-06-28   \n",
       "20366  BEN GURBETIN KUCAGINDA DÃœSÃ‰ KALKA YORULDUM BIR...  1991-08-06   \n",
       "21101  Siyah perÃ§emlerin gonca yÃ¼zlerin Garip bÃ¼lbÃ¼l ...  2001-08-23   \n",
       "22154  Bilmez misin ben bir tek sana yandÄ±m yine sana...  2018-01-24   \n",
       "22157  Son noktasÄ±na kadar sÃ©N yazdÄ±rdÄ±n sonunda yaln...  2018-01-24   \n",
       "27489  Kalplerimiz bir olsa SevdamÄ±z baÅŸka baÅŸka Olsu...  1989-06-13   \n",
       "38708  oturdugu yerden kaLkmas hicÃŸirseyi umursamaz i...  2005-09-13   \n",
       "49124  Sevdaya DÃ¼ÅŸeli Yaram Derindir SÃ¶yleyin Dostlar...        2004   \n",
       "51120  Hani cok sevmistin beni ne oldu sana gÃ¼lÃ¼m Ner...  2001-03-16   \n",
       "53589  AÄŸÄ±r kapÄ± aksak lisan Kelimeler yetmiyor Ã‡Ä±pla...  1996-08-26   \n",
       "53602  Bir Ã§apkÄ±n dilencidansederek gezip durur ÅŸehri...        2001   \n",
       "54753  Ah Nice bir uyursun uyanmaz mÄ±sÄ±n GÃ¶cdÃ¼ kervan...  2005-09-29   \n",
       "\n",
       "                                   name  \n",
       "7199                           Bekarlar  \n",
       "10877                Geceler Yarim Oldu  \n",
       "14731                          Alamanya  \n",
       "19378                              AÄŸÄ±t  \n",
       "20366               Ä°ki GÃ¶zÃ¼m Ä°ki Ã‡eÅŸme  \n",
       "21101  Siyah PerÃ§emlerin Gonca YÃ¼zlerin  \n",
       "22154                  CanÄ±na KÄ±yamadÄ±m  \n",
       "22157                           Ä°nadÄ±na  \n",
       "27489              Kalplerimiz Bir Olsa  \n",
       "38708                           KÄ±mÄ±lda  \n",
       "49124                    Sevdaya DÃ¼ÅŸeli  \n",
       "51120                             GÃ¼lÃ¼m  \n",
       "53589                         AÄŸÄ±r KapÄ±  \n",
       "53602                Bir Ã‡apkÄ±n Dilenci  \n",
       "54753               Ah Nice Bir Uyursun  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].str.contains('[Ã¥Ã¯ÃŸÂ£Ã°Ã‰Â¡Ã¤Å¾Ã“Â¢ÃÄÃ‘Ã©Ã±Â¿Ã«ÃºÃ¬Ã Ã‹ÃˆÂ®Ã²ÃƒÂ¶Å¡Å‘Ã£Ã½Ã¾Ã¨Ã³Ã¦Ã¡ÃšÅ“Ã›Ã­Ã¹Ã¸Âª]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../assets/lyrics/master_data_20180626.csv\", index_col=0)\n",
    "df = grooming_language(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_weird_chars(text_col):\n",
    "    text_col = text_col.str.replace('Ã¤', 'a')\n",
    "    text_col = text_col.str.replace('Ã¡', 'a')\n",
    "    text_col = text_col.str.replace('ÃŸ', 'b')\n",
    "    text_col = text_col.str.replace('ÃƒÂ¢', 'a')\n",
    "    text_col = text_col.str.replace('Ã‰', 'E')\n",
    "    text_col = text_col.str.replace('Ãƒâ€š', 'A')\n",
    "    text_col = text_col.str.replace('Ã©', 'e')\n",
    "    text_col = text_col.str.replace('Ã°', 'ÄŸ')\n",
    "    text_col = text_col.str.replace('w', 'v')\n",
    "    text_col = text_col.str.replace('gÃ¶anÃ¼l', 'gÃ¶nÃ¼l')\n",
    "    text_col = text_col.str.replace('Ãº', 'u')\n",
    "    text_col = text_col.str.replace('Ã½', 'Ä±')\n",
    "    text_col = text_col.str.replace('Ã­', 'i')\n",
    "    text_col = text_col.str.replace('SÃ¶z  Fikret ÅeneÅŸ & MÃ¼zik  Diques Fleche', '')\n",
    "    text_col = text_col.str.replace('Icqum 150' , '')\n",
    "    text_col = text_col.str.replace('Montesquieuyu' , '')\n",
    "    return text_col\n",
    "\n",
    "def drop_more_wrong_language(df):\n",
    "    df.drop(df[df['text'].str.contains('qu')].index, inplace = True)\n",
    "    df.drop(df[(df['text'].str.contains('of') & df['text'].str.contains('my')) | (df['text'].str.contains('the') & df['text'].str.contains('you'))].index, inplace = True)\n",
    "    df.drop(df[(df['text'].str.contains('your'))].index, inplace = True)\n",
    "    df.drop(df[(df['text'].str.contains(' for '))].index, inplace = True)\n",
    "    df.drop(df[(df['text'].str.contains(' For '))].index, inplace = True)\n",
    "    df.drop(df[(df['text'].str.contains(' With '))].index, inplace = True)\n",
    "    df.drop(df[(df['text'].str.contains(' love '))].index, inplace = True)\n",
    "    df.drop(df[(df['text'].str.contains('Love'))].index, inplace = True)\n",
    "    df.drop(df[(df['text'].str.contains(' Ã§i '))].index, inplace = True)\n",
    "    df = df[df['artist'] != 'Agire Jiyan']\n",
    "    df = df[df['artist'] != 'Abidin Biter']\n",
    "    return df\n",
    "\n",
    "def clean_bad_langauge(df):\n",
    "    \"\"\"Wrapper for grooming_langauge, replace_weird_chars, and drop_more_wrong_language\"\"\"\n",
    "    df = grooming_language(df)\n",
    "    df['text'] = replace_weird_chars(df['text'])\n",
    "    df = drop_more_wrong_language(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing... does this all work together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df loaded.\n",
      "               artist            album  \\\n",
      "285             Abdal   Ervah-I Ezelde   \n",
      "286             Abdal   Ervah-I Ezelde   \n",
      "289             Abdal   Ervah-I Ezelde   \n",
      "292             Abdal   Ervah-I Ezelde   \n",
      "296  Abdullah Akbulak  Zakirin GÃ¶zyaÅŸÄ±   \n",
      "\n",
      "                                                  text     release  \\\n",
      "285  AltÄ±n yÃ¼zÃ¼ÄŸÃ¼m kÄ±rÄ±ldÄ± hey Suya dÃ¼ÅŸtÃ¼ su duruld...  2013-03-16   \n",
      "286  Bir baÄŸ bozumuydu gidiÅŸin Plajlar boÅŸalmÄ±ÅŸtÄ± B...  2011-12-02   \n",
      "289  Bir of Ã§eksem karÅŸÄ± ki daÄŸlar yÄ±kÄ±lÄ±r BugÃ¼n po...  2011-12-02   \n",
      "292  EÄŸin dedikleri anam bir kÃ¼Ã§Ã¼k ÅŸehir nidem Nine...  2011-12-02   \n",
      "296  SubhanÄ±m Allah sultanÄ±m Allah MaÄŸrifet eden ra...  2003-11-07   \n",
      "\n",
      "                                     name  \n",
      "285                 AltÄ±n YÃ¼zÃ¼ÄŸÃ¼m KÄ±rÄ±ldÄ±  \n",
      "286                             BaÄŸbozumu  \n",
      "289  Bir Of Ã‡eksem KarÅŸÄ±ki DaÄŸlar YÄ±kÄ±lÄ±r  \n",
      "292        EÄŸin Dedikleri Bir KÃ¼Ã§Ã¼k Åehir  \n",
      "296                                Acizim  \n"
     ]
    }
   ],
   "source": [
    "%run ../scripts/post_scraping_text_processing.py load # put anything other than functions here to run the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
